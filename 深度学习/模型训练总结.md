### 1、数据准备

​		主要是针对采集的数据做一些预处理的工作，基础的入空值填充，异常值处理等等。

#### 1.1 数据标准化

​		使用sklearn.preprocessing里的一些工具可以很方便的将**数据标准化**或者归一化送入模型进行训练，模型输出的结果也可以很方便的使用**保存的归一化工具** 进行**反归一化**。

1. `StandardScaler`: 标准化工具，将特征数据进行标准化处理，使得数据符合标准正态分布（均值为0，标准差为1）。目的是消除特征间的量纲差异，使得各特征之间对模型训练的贡献更为均衡。

    ```python\
    from sklearn.preprocessing import StandardScaler
    # 创建数据
    data = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])
    # 实例化StandardScaler
    scaler = StandardScaler()
    # 拟合和转换数据
    scaled_data = scaler.fit_transform(data)
    ```

2. `MinMaxScaler`: 将特征缩放到给定的最大值和最小值之间。（通常是0 - 1）

    ```python
    from sklearn.preprocessing import MinMaxScaler
    # 创建数据
    data = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])
    # 实例化StandardScaler
    scaler = StandardScaler()
    # 拟合和转换数据
    scaled_data = scaler.fit_transform(data)
    ```

3. `MinMaxScaler`：将特征缩放到 [-1, 1] 范围内，但保留稀疏性。

4. `RobustScaler`：使用中位数和四分位数进行缩放，对于含有异常值的数据更稳健。

​	标准化方法有很多，都有其特定的应用场景，选择合适的方法取决于数据的特性和具体的任务需求。

#### 1.2 将标准化的scaler保存，后面用于反归一化

​		主要是用dump、load等函数，scaler的fit_transform\transform\inverse_transform等一些方法。

```python
# 实例化StandardScaler
scaler = StandardScaler()
train_data = scaler.fit_transform(data)
# 保存实例化模型
dump(scaler, "model/train_scaler.pkl")
...
# 加载实例化模型
scaler = load("model/train_scaler.pkl")
# 标准化数据
train_data = scaler.transform(data)

# 反归一化
data = scaler.inverse_transform(train_data)
```



